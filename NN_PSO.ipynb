{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Swarm Optimization on Neural Networks\n",
    "#### References\n",
    "\n",
    "- J. Kennedy and R. Eberhart, \"Particle swarm optimization,\" Proceedings of ICNN'95 - International Conference on Neural Networks, Perth, WA, Australia, 1995, pp. 1942-1948 vol.4, doi: 10.1109/ICNN.1995.488968.\n",
    "- M. Kaminski, \"Neural Network Training Using Particle Swarm Optimization - a Case Study,\" 2019 24th International Conference on Methods and Models in Automation and Robotics (MMAR), Miedzyzdroje, Poland, 2019, pp. 115-120, doi: 10.1109/MMAR.2019.8864679."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
      "0   1   25           1      49     91107       4    1.6          1         0   \n",
      "1   2   45          19      34     90089       3    1.5          1         0   \n",
      "2   3   39          15      11     94720       1    1.0          1         0   \n",
      "3   4   35           9     100     94112       1    2.7          2         0   \n",
      "4   5   35           8      45     91330       4    1.0          2         0   \n",
      "\n",
      "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
      "0              0                   1           0       0           0  \n",
      "1              0                   1           0       0           0  \n",
      "2              0                   0           0       0           0  \n",
      "3              0                   0           0       0           0  \n",
      "4              0                   0           0       0           1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "print(data.head())\n",
    "\n",
    "df = data\n",
    "df = df.drop(['ID','ZIP Code','Personal Loan'],axis=1)\n",
    "df['Personal Loan'] = data['Personal Loan']\n",
    "\n",
    "\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X= scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(X , y , test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def derivative_sig(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "def forward(\n",
    "    X, y, input_layer,W1,W2, hidden1, output_layer, iter_, learning_rate\n",
    "):\n",
    "    # weights =[]\n",
    "    # act =[]\n",
    "\n",
    "    # weights=[W1,W2]\n",
    "\n",
    "    for i in range(iter_):\n",
    "\n",
    "        z1 = np.dot(X, W1)\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = np.dot(a1, W2)\n",
    "        y_pred = sigmoid(z2)\n",
    "\n",
    "        error = mean_squared_error(y, y_pred)\n",
    "        delta3 = (y_pred - y) * derivative_sig(y_pred)\n",
    "\n",
    "        dW2 = np.dot(a1.T, delta3)\n",
    "        delta2 = np.dot(delta3, W2.T) * derivative_sig(a1)\n",
    "\n",
    "        dW1 = np.dot(X.T, delta2)\n",
    "\n",
    "        W1 -= learning_rate * dW1\n",
    "        W2 -= learning_rate * dW2\n",
    "\n",
    "    print(f\"Error after {iter_} : {error}\")\n",
    "\n",
    "    return W1, W2\n",
    "\n",
    "\n",
    "def PSO(X, y, W1, W2, iter_, particle_count, var1, var2, var3):\n",
    "    \n",
    "    bst_weights = np.zeros(W1.size + W2.size)\n",
    "    error_ = np.inf\n",
    "    \n",
    "    ps_pos = np.random.uniform(-1, 1, size=(particle_count, W1.size + W2.size))\n",
    "    ps_vel = np.zeros_like(ps_pos)\n",
    "    ps_bstpos = np.copy(ps_pos)\n",
    "    ps_error = np.ones(particle_count) * np.inf\n",
    "    \n",
    "    for i in range(iter_):\n",
    "        for j in range(particle_count):\n",
    "\n",
    "            weights_ = ps_pos[j]\n",
    "            W1 = weights_[:W1.size].reshape(W1.shape)\n",
    "            W2 = weights_[W1.size:].reshape(W2.shape)\n",
    "            \n",
    "            y_hat = sigmoid(np.dot(sigmoid(np.dot(X, W1)), W2))\n",
    "            error = np.mean(np.square(y - y_hat))\n",
    "            \n",
    "            if error < ps_error[j]:\n",
    "                ps_bstpos[j] = weights_.copy()\n",
    "                ps_error[j] = error\n",
    "            \n",
    "            if error < error_:\n",
    "                bst_weights = weights_.copy()\n",
    "                error_ = error\n",
    "            \n",
    "            delta3 = (y_hat - y) * derivative_sig(y_hat)\n",
    "            dW2 = np.dot(sigmoid(np.dot(X, W1)).T, delta3)\n",
    "            delta2 = np.dot(delta3, W2.T) * derivative_sig(sigmoid(np.dot(X, W1)))\n",
    "            dW1 = np.dot(X.T, delta2)\n",
    "            \n",
    "            ps_vel[j] = var1 * ps_vel[j] + var2 * np.random.rand() * (ps_bstpos[j] - weights_) + var3 * np.random.rand() * (bst_weights - weights_)\n",
    "            ps_pos[j] += ps_vel[j]\n",
    "        \n",
    "    W1 = bst_weights[:W1.size].reshape(W1.shape)\n",
    "    W2 = bst_weights[W1.size:].reshape(W2.shape)\n",
    "    return W1, W2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report after 1000 :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         2\n",
      "           1       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.71         7\n",
      "   macro avg       0.75      0.80      0.71         7\n",
      "weighted avg       0.86      0.71      0.73         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_layer = X.shape[1]\n",
    "hidden1 = 4\n",
    "output_layer = 1\n",
    "\n",
    "W1 = np.random.randn(X.shape)\n",
    "W2 = np.random.randn(y.shape)\n",
    "learning_rate=0.01\n",
    "iter_ = 100\n",
    "particle_count = 50\n",
    "var1 = 0.5\n",
    "var2 = 1\n",
    "var3 = 1\n",
    "W1 = np.random.randn(input_layer, hidden1)\n",
    "W2 = np.random.randn(hidden1, output_layer)\n",
    "w1,w2 =forward(x_train,y_train,W1,W2,input_layer,hidden1,output_layer,iter_,learning_rate)\n",
    "# print(f\"\\nInitial Population weight :\\n{w1,w2}\\n\")\n",
    "# print(f\"After ACO :\\n{PSO(x_train,y_train,w1,w2,iter_,particle_count,var1,var2,var3)}\")\n",
    "W1,W2 = PSO(x_train,y_train,w1,w2,iter_,particle_count,var1,var2,var3)\n",
    "w1,w2 =forward(x_test,y_test,W1,W2,input_layer,hidden1,output_layer,iter_,learning_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
